---
title: "Session 5: Standard error, Bootstrapping and confidence intervals"
format: html
---

This week we will continue the stats training by studying three important concepts; standard error (Video 1), bootstrapping (Video 2) and confidence intervals (Video 3).   

Start by watching [Video 1](https://youtu.be/XNgt7F6FqDU?si=XZe8zkm1IDDxvwfl){target="_blank"} (*The standard error, Clearly Explained!!!*). 

1. In the video, Josh mentions that the standard error is the standard deviation of multiple means taken from the same population. So if there is a population and we can take a bunch of different samples from it, all we have to do to get the the standard error is to calculate the standard deviation of the means of each sample. He illustrates this idea with an example (starting at 2:44). Here samples of mice weight measurements are taken (the example is a bit weird since it is difficult to imagine what a mouse with negative weight would look like, but anyway...), and the sampling is repeated three times. This hardly qualifies as "a bunch of times". Your job is to replicate this example but instead of taking three samples take 10,000. Use the visuals and table in the example to determine/guess the population parameters (speaking of weirdness, does the normal curve in the example seem right to you?). If you think this exercise is quite similar to something we did the week when we learned about variance and standard deviation, you are on the right track.   

2. When taking samples to calculate the standard error, why is it important to do so "a bunch of times", and how many times are enough? Study the code in the code chunk below and explain what each part does. Run the code (it will take a minute or two) and explain what you see in the plot. Use the `ggsave()` function to save the plot as a file, so that you can share it easily in the zoom chat come Thursday. Is the pattern (in terms of convergence) affected by the sample size of each individual sample (the number the `n` argument is set to in `rnorm()`)? 

```{r}
#| eval: false
log10_seq <- as.integer(10 ^ (seq(1, 5, .1)))

log10_seq_names <- set_names(log10_seq)

map(log10_seq_names, \(i) {
  map(1:i, \(x) tibble(values = rnorm(n = 20, mean = 20, sd = 10))) %>% 
    list_rbind(names_to = "sample")
}) %>%
  list_rbind(names_to = "n_samples") %>% 
  group_by(n_samples, sample) %>% 
  summarise(m = mean(values)) %>% 
  group_by(n_samples) %>% 
  summarise(sterr = sd(m)) %>% 
  mutate(n_samples = as.numeric(n_samples)) %>% 
  ggplot(aes(x = n_samples,
             y = sterr)) +
  geom_line() +
  scale_x_continuous(trans = 'log10')
```

Now watch [Video 2](https://youtu.be/Xz0x-8-cgaQ?si=xFJeubpWZXvJsNvD){target="_blank"} (*Bootstrapping Main Ideas!!!*)

3. We will now use our R skills to calculate the standard error in three different ways; via simulation, bootstrapping and formula. To practice this we will use data from the `palmerpenguins` package. This package, as the name suggests, contains data on penguins and you can read more about the data [here](https://allisonhorst.github.io/palmerpenguins/){target="_blank"}. Start by installing and loading the package. Once the package is loaded you will be able to work with the data by referencing the object `penguins`.

  * We will focus on the *Adelie* species of penguins and calculate the standard error of the mean bill length (`bill_length_mm`). But first, make a histogram showing the distribution of bill lengths for this species. 

  * By now you should a have a pretty good idea how you could go about calculating the standard error of the mean using simulation, in other words by sampling repeatedly from a normally distributed population with parameters estimated from the sample of Adelie penguins (Hint: you should be able to reuse some code from exercise 1). Think about how to best handle missing values in this case and in general when calculating the standard error. 

  * Next, we turn to bootstrapping. Since we haven't covered bootstrapping in R yet, we provide the code below. Per usual, study the code and make sure you understand what each part does. What does the distribution of bootstrapped means look like? 
  
```{r}
#| eval: false
boot <- function(data){
  data %>% 
    slice_sample(prop = 1, replace = TRUE)
}

Adelie_no_missing <- penguins %>% 
  filter(species == "Adelie", 
         !is.na(bill_length_mm)) 

Adelie_boot <- map(1:10000, \(i) boot(Adelie_no_missing)) %>% 
  list_rbind(names_to = "iteration")

Adelie_boot %>% 
  group_by(iteration) %>% 
  summarize(m = mean(bill_length_mm)) %>% 
  summarize(strerr = sd(m))
```

  * Josh briefly mentioned in Video 1 that in rare cases there is a formula that can be used to estimate the standard error. There is such a formula for the standard error of the mean and it is simply the standard deviation divided by the square root of the sample size. Use this formula to calculate the standard error of the mean for Adelie penguin bill length. 
  
  * How do the standard errors or the mean from the three different calculations compare? 

4. Calculate the correlation between bill length and body mass in Adelie penguins (hint: use `summarize()` and `cor()`). 

  * Pick one of the three methods from exercise 3 to calculate the standard error of the correlation. 
  

We are ready to start thinking about confidence intervals. Check out [Video 3](https://youtu.be/TqOeMYtOc1w?si=1lA81N7A7nnaShfm){target="_blank"} (*Confidence Intervals, Clearly Explained!!!*)

Josh explains that a 95% confidence interval is just an interval that covers 95% of the (bootstrapped) means, or whatever statistic we decide to focus on. 

5. Use bootstrapping to calculate the 95% confidence interval of the mean bill length in Adelie penguins. To find the interval that covers 95% of the bootstrapped means, use the `summarize()` and `quantile()` functions (for example `summarize(lower_CI = quantile(bootstrapped_means, probs = 0.025))`).

  * Do the same thing as above for the other two species of penguins in the `penguins` data frame. Plot the mean and 95% confidence intervals for the three species side by side in the same plot. Use `geom_pointrange()` for this. Do the penguin species differ significantly with regards to mean bill length? 
  
  * Repeat the confidence interval generating process, but this time instead of focusing on the mean bill length, investigate the correlation between bill length and body mass. Are the correlations statistically different from zero? Are they significantly different from 0.5? What conclusions do you draw when comparing the different species? 
  
  * Which species has the widest confidence intervals (look at both mean and correlation)? Think about why this is the case. 
  
6. We have defined 95% confidence intervals as an interval that contains 95% of means calculated when bootstrapping the sample. While this is correct and an intuitive way to think to think about confidence intervals, the formal definition of a confidence interval is a little bit different (and more general). We don't want you to get bogged down with the minutia of definitions here, but it could be good to at least take a look at a nice visualization illustrating the more general way of defining confidence intervals. Check out the visualization found [here](https://rpsychologist.com/d3/ci/){target="_blank"}. Can you infer the definition of confidence intervals from this visualization? 



